{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSA0TllDwUhh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import nltk\n",
        "from joblib import dump, load\n",
        "from collections import Counter\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt6s_AQswUhu"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"../data/train_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t08-uIciwUh0"
      },
      "source": [
        "### Collecting stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbxKyULiwUh-"
      },
      "outputs": [],
      "source": [
        "all_words = []\n",
        "for sen in data.text.values:\n",
        "    all_words.extend(sen.strip().split(\" \"))\n",
        "    \n",
        "word_counts = dict(Counter(all_words).most_common())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5lBbEzVwUiD",
        "outputId": "70cddda5-5624-400c-aade-a380efaceb59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_stop_words = 26\n",
        "stop_words = []\n",
        "for key,value in enumerate(word_counts,0):\n",
        "    if(key<n_stop_words):\n",
        "        stop_words.append(value)\n",
        "    \n",
        "len(stop_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KflDDr37wUiI"
      },
      "source": [
        "### Encoding labels\n",
        "Classes are encoded with int labels from 0 to 17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6gWWRP2wUiN",
        "outputId": "fc04677f-60a0-4e7a-f0c3-6fef3d954bc1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>length</th>\n",
              "      <th>dialect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>لكن بالنهايه ينتفض يغير</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>يعني هذا محسوب علي البشر حيونه وحشيه وتطلبون م...</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>مبين من كلامه خليجي</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>وين هل الغيبه اخ محمد</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  length  dialect\n",
              "0                            لكن بالنهايه ينتفض يغير       4        4\n",
              "1  يعني هذا محسوب علي البشر حيونه وحشيه وتطلبون م...      15        4\n",
              "2                                مبين من كلامه خليجي       4        4\n",
              "3                          يسلملي مرورك وروحك الحلوه       4        4\n",
              "4                              وين هل الغيبه اخ محمد       5        4"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "data[\"dialect\"] = le.fit_transform(data[\"dialect\"])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EbKKfoEwUiQ",
        "outputId": "b74fbf4a-613e-4837-e6fc-4b97c8f91b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'AE', 1: 'BH', 2: 'DZ', 3: 'EG', 4: 'IQ', 5: 'JO', 6: 'KW', 7: 'LB', 8: 'LY', 9: 'MA', 10: 'OM', 11: 'PL', 12: 'QA', 13: 'SA', 14: 'SD', 15: 'SY', 16: 'TN', 17: 'YE'}\n"
          ]
        }
      ],
      "source": [
        "labels_dict = {key:value for key,value in enumerate(le.classes_,0)}\n",
        "print(labels_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om7WkCAYwUiV"
      },
      "source": [
        "### Preparing data for training\n",
        "- Splitting training and test data\n",
        "- Initializing label probabilities for the ComplementNB model used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYDmkkLTwUib"
      },
      "outputs": [],
      "source": [
        "train_X,test_X,train_y,test_y = train_test_split(data[\"text\"],\n",
        "                                                 data[\"dialect\"],\n",
        "                                                 test_size=0.1,\n",
        "                                                 random_state=42,\n",
        "                                                 stratify=data[\"dialect\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PqoWOPkwUih"
      },
      "outputs": [],
      "source": [
        "labels = data.groupby(\"dialect\")[\"text\"].count()\n",
        "prob = (labels/labels.sum()).values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0vq8sMMwUil"
      },
      "source": [
        "### Creating and training the model\n",
        "Creating a ComplementNB model with a grid search cross validation (10 folds). Text is represented in a TFIDF matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zX2L95qwUin"
      },
      "outputs": [],
      "source": [
        "cv = GridSearchCV(ComplementNB(),{\"norm\":[True,False],\"class_prior\":[prob,None],\"alpha\":np.arange(0.1,1.0,0.2)},cv=10,n_jobs=-1,scoring=\"accuracy\")\n",
        "model = Pipeline(steps=[(\"count\",TfidfVectorizer(ngram_range=(1,2),stop_words = stop_words)),(\"model\",cv)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLao6x6mwUis"
      },
      "outputs": [],
      "source": [
        "model.fit(train_X.values,train_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HJ_9p_TwUiv"
      },
      "source": [
        "### Evaluating and saving the best model\n",
        "Generating predictions for the test set and evaluating model performance with classification report. Tracking experiments in a simple .txt file.\n",
        "Saving the best model manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPzAvmHgwUix",
        "outputId": "3ece2f14-41c4-4b1b-bb93-4e568d638dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'count': TfidfVectorizer(ngram_range=(1, 2),\n",
            "                stop_words=['من', 'في', 'ما', 'اللي', 'و', 'علي', 'الله', 'بس',\n",
            "                            'يا', 'انا', 'كل', 'مش', 'ولا', 'لا', 'والله', 'هه',\n",
            "                            'ان', 'لو', 'شي', 'انت', 'مع', 'عن', 'كان', 'الي',\n",
            "                            'ع', '؟']), 'model': GridSearchCV(cv=10, estimator=ComplementNB(), n_jobs=-1,\n",
            "             param_grid={'alpha': array([0.1, 0.3, 0.5, 0.7, 0.9]),\n",
            "                         'class_prior': [array([0.05745602, 0.05739255, 0.03530048, 0.12581362, 0.03382534,\n",
            "       0.06085059, 0.09204081, 0.06025747, 0.07958749, 0.0252065 ,\n",
            "       0.04171755, 0.09540474, 0.06790894, 0.05862037, 0.03135218,\n",
            "       0.03544055, 0.02019234, 0.02163246]),\n",
            "                                         None],\n",
            "                         'norm': [True, False]},\n",
            "             scoring='accuracy')}\n",
            "  accuracy 0.5371079643693506 \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.40      0.44      2625\n",
            "           1       0.45      0.29      0.35      2622\n",
            "           2       0.67      0.51      0.58      1613\n",
            "           3       0.55      0.93      0.69      5749\n",
            "           4       0.74      0.51      0.60      1546\n",
            "           5       0.48      0.27      0.34      2780\n",
            "           6       0.43      0.65      0.52      4206\n",
            "           7       0.60      0.70      0.65      2753\n",
            "           8       0.68      0.69      0.68      3636\n",
            "           9       0.77      0.62      0.68      1152\n",
            "          10       0.52      0.26      0.35      1906\n",
            "          11       0.48      0.55      0.51      4359\n",
            "          12       0.47      0.53      0.50      3103\n",
            "          13       0.46      0.40      0.43      2678\n",
            "          14       0.79      0.45      0.57      1433\n",
            "          15       0.50      0.20      0.28      1619\n",
            "          16       0.76      0.43      0.55       923\n",
            "          17       0.52      0.17      0.25       988\n",
            "\n",
            "    accuracy                           0.54     45691\n",
            "   macro avg       0.58      0.48      0.50     45691\n",
            "weighted avg       0.55      0.54      0.52     45691\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(test_X)\n",
        "score = accuracy_score(test_y,preds)\n",
        "with open(\"results.txt\",\"a\",encoding=\"utf-8\") as file:\n",
        "    score_text = str(model.named_steps) + \"\\n  accuracy %s \\n\\n\" %(score)\n",
        "    file.write(score_text)\n",
        "    \n",
        "print(score_text)\n",
        "print(classification_report(test_y,preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mVJFbpNwUi0",
        "outputId": "8d110214-529c-4e75-bb4d-e26628cacb79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['cnb_054.joblib']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dump(model,\"../models/cnb_054.joblib\")\n",
        "with open(\"../models/labels_dict.pickle\",\"rb\") as file:\n",
        "  pickle.dump(labels_dict,file,protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXCwgb5xwUi4"
      },
      "outputs": [],
      "source": [
        "# cnb = load(\"cnb_053.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pULzJCw6wUi6",
        "outputId": "f3d9f9e4-9658-422f-b6aa-5808d1be0092"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5365608106629314"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# accuracy_score(test_y,preds)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ml_model.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
