{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9VzYkBIKNfFc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import regex as re\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vjXQeX4zOtJ0",
        "outputId": "ada43111-ecaa-4824-9b51-8f879932bf3d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>length</th>\n",
              "      <th>dialect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>لكن بالنهايه ينتفض يغير</td>\n",
              "      <td>4</td>\n",
              "      <td>IQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>يعني هذا محسوب علي البشر حيونه وحشيه وتطلبون م...</td>\n",
              "      <td>15</td>\n",
              "      <td>IQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>مبين من كلامه خليجي</td>\n",
              "      <td>4</td>\n",
              "      <td>IQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
              "      <td>4</td>\n",
              "      <td>IQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>وين هل الغيبه اخ محمد</td>\n",
              "      <td>5</td>\n",
              "      <td>IQ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  length dialect\n",
              "0                            لكن بالنهايه ينتفض يغير       4      IQ\n",
              "1  يعني هذا محسوب علي البشر حيونه وحشيه وتطلبون م...      15      IQ\n",
              "2                                مبين من كلامه خليجي       4      IQ\n",
              "3                          يسلملي مرورك وروحك الحلوه       4      IQ\n",
              "4                              وين هل الغيبه اخ محمد       5      IQ"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_path = \"../data/train_data.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8meRxNiPC8k"
      },
      "source": [
        "### Building vocab, word2idx, idx2word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eXxBpexGPHw5"
      },
      "outputs": [],
      "source": [
        "all_words = []\n",
        "for sen in data.text.values:\n",
        "  for word in sen.split():\n",
        "    all_words.append(word)\n",
        "\n",
        "word_counts = dict(Counter(all_words).most_common())\n",
        "vocab = set(all_words)\n",
        "vocab_size = len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL7RPiRiPKyQ",
        "outputId": "85c3696b-3f1f-4d47-8ceb-246058582a72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "384718"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx2word = {k:v for k, v in enumerate(vocab,1)}\n",
        "word2idx = {v:k for k, v in idx2word.items()}\n",
        "len(word2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_e0_uVFqPM1W"
      },
      "outputs": [],
      "source": [
        "def create_sequence(text):\n",
        "  seq = []\n",
        "  for word in text.split():\n",
        "    seq.append(word2idx[word])\n",
        "\n",
        "  return seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "392wJkBbPOl4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>length</th>\n",
              "      <th>dialect</th>\n",
              "      <th>sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>لكن بالنهايه ينتفض يغير</td>\n",
              "      <td>4</td>\n",
              "      <td>IQ</td>\n",
              "      <td>[172935, 140888, 295891, 35701]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>يعني هذا محسوب علي البشر حيونه وحشيه وتطلبون م...</td>\n",
              "      <td>15</td>\n",
              "      <td>IQ</td>\n",
              "      <td>[360600, 197728, 357121, 376645, 350968, 14251...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>مبين من كلامه خليجي</td>\n",
              "      <td>4</td>\n",
              "      <td>IQ</td>\n",
              "      <td>[337280, 114447, 264086, 97023]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
              "      <td>4</td>\n",
              "      <td>IQ</td>\n",
              "      <td>[251918, 350104, 263315, 251639]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>وين هل الغيبه اخ محمد</td>\n",
              "      <td>5</td>\n",
              "      <td>IQ</td>\n",
              "      <td>[259902, 20333, 209035, 234356, 297674]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  length dialect  \\\n",
              "0                            لكن بالنهايه ينتفض يغير       4      IQ   \n",
              "1  يعني هذا محسوب علي البشر حيونه وحشيه وتطلبون م...      15      IQ   \n",
              "2                                مبين من كلامه خليجي       4      IQ   \n",
              "3                          يسلملي مرورك وروحك الحلوه       4      IQ   \n",
              "4                              وين هل الغيبه اخ محمد       5      IQ   \n",
              "\n",
              "                                            sequence  \n",
              "0                    [172935, 140888, 295891, 35701]  \n",
              "1  [360600, 197728, 357121, 376645, 350968, 14251...  \n",
              "2                    [337280, 114447, 264086, 97023]  \n",
              "3                   [251918, 350104, 263315, 251639]  \n",
              "4            [259902, 20333, 209035, 234356, 297674]  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"sequence\"] = data.text.apply(create_sequence)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubpOEs9oPQUt"
      },
      "source": [
        "### Removing invalid data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dp6E4o2VQIio"
      },
      "outputs": [],
      "source": [
        "n_words = 25\n",
        "stop_words = list(word_counts.keys())[:n_words]\n",
        "stop_idx = [word2idx[w] for w in stop_words]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53XRY4yxQK24"
      },
      "outputs": [],
      "source": [
        "def remove_stop_words(seq):\n",
        "  s = seq\n",
        "  for el in s:\n",
        "    if el in stop_words:\n",
        "      s.remove(s)\n",
        "\n",
        "  return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6CggiffRXIL"
      },
      "outputs": [],
      "source": [
        "data.sequence = data.sequence.apply(remove_stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2Q_3emXPQx1"
      },
      "outputs": [],
      "source": [
        "data[\"length\"] = data.sequence.str.len()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km_JKBL6SRRw"
      },
      "source": [
        "### Preparing data for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rwCOFYeSUE6"
      },
      "outputs": [],
      "source": [
        "longest_seq = data.length.max()\n",
        "shortest_seq = data.length.min()\n",
        "avg_seq = data.length.mean()\n",
        "\n",
        "print(\"Longest text: %s\\nShortest text: %s\\nAverage text length: %s\\n\"%(longest_seq,shortest_seq,avg_seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBrGv10BT5MB"
      },
      "outputs": [],
      "source": [
        "seq_size = 20\n",
        "embedding_size = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKmCODuHUIe_"
      },
      "outputs": [],
      "source": [
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(data.dialect)\n",
        "sequences = pad_sequences(data.sequence,maxlen=seq_size)\n",
        "\n",
        "class_labels = {k:v for k,v in enumerate(lb.classes_,0)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmTOp0bFVkxF"
      },
      "outputs": [],
      "source": [
        "train_X, remain_X, train_y, remain_y = train_test_split(sequences,labels,train_size=0.9,stratify=labels,random_state=42)\n",
        "test_X, val_X, test_y, val_y = train_test_split(remain_X,remain_y, train_size=0.5, stratify=remain_y, random_state=42)\n",
        "\n",
        "print(\"Train size: %s\\nTest size: %s\\nValidation size: %s\\n\"%(len(train_X),len(test_X),len(val_X)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM5dF3oMVX2w"
      },
      "outputs": [],
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((train_X, train_y))\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test_X,test_y))\n",
        "val_data = tf.data.Dataset.from_tensor_slices((val_X,val_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3g0ytszYB1Q"
      },
      "outputs": [],
      "source": [
        "batch_size = 1000\n",
        "\n",
        "train_data = train_data.shuffle(100).batch(batch_size)\n",
        "test_data = test_data.batch(batch_size)\n",
        "val_data = val_data.shuffle(100).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7EKfBk6YIJn"
      },
      "source": [
        "### Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QJQvDgokdfZ"
      },
      "outputs": [],
      "source": [
        "training_hist = pd.DataFrame(columns=[\"summary\",\"loss\",\"acc\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Qc1v1DmYKjO"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Embedding(vocab_size+1,embedding_size,embeddings_initializer=keras.initializers.GlorotNormal()))\n",
        "model.add(keras.layers.LSTM(100,return_sequences=True))\n",
        "model.add(keras.layers.LSTM(50))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(100,activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(18,activation=\"softmax\"))\n",
        "\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=0.001)\n",
        "model.compile(loss=loss,optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50xz8ZDP7aXd"
      },
      "source": [
        "### Training, evaluating, and saving the best model\n",
        "Training the model with early stopping and checkpoint monitored by validation accuracy. Evaluation is done through classification report.\n",
        "All experiments are added to a dataframe along with their accuracy and loss values.\n",
        "Saving best model and the word2idx dict for deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUD7Rv6kYVsR"
      },
      "outputs": [],
      "source": [
        "callbacks = [keras.callbacks.EarlyStopping(patience=5,monitor=\"val_accuracy\",mode=\"max\",restore_best_weights=True),\n",
        "             keras.callbacks.ModelCheckpoint(filepath='./models/model{val_accuracy:.3f}.h5',save_best_only=True, monitor=\"val_accuracy\",mode=\"max\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7PRsrsUYY2I"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_data,validation_data=val_data,epochs=500,callbacks=callbacks)\n",
        "\n",
        "scores = model.evaluate(test_X,test_y)\n",
        "stats =pd.DataFrame({\"summary\":[[layer.name for layer in model.layers]],\"loss\":scores[0],\"acc\":scores[1]})\n",
        "training_hist = pd.concat((training_hist, stats), axis=0)\n",
        "\n",
        "preds = np.argmax(model.predict(test_X),axis=1)\n",
        "truth = np.argmax(test_y,axis=1)\n",
        "print(classification_report(truth,preds))\n",
        "training_hist.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"../models/word2idx.pickle\",\"wb\") as handle:\n",
        "    pickle.dump(word2idx,handle,protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of manual_embeddings.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
